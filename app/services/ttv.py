# services/ttv.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
CogVideoXâ€‘1.5 ê¸°ë°˜ í…ìŠ¤íŠ¸â€‘íˆ¬â€‘ë¹„ë””ì˜¤(TTV) ëª¨ë“ˆ
- fp16 + 4â€‘bit NF4 + int8 weightâ€‘only
- â˜… GPUê°€ ì—†ê±°ë‚˜ SKIP_MODEL_LOAD=1 ì¼ ë•ŒëŠ” ëª¨ë¸ì„ ê±´ë„ˆë›´ë‹¤!
"""
from __future__ import annotations

import os, torch
from datetime import datetime
from pathlib import Path
from typing import List

from diffusers.utils import export_to_video
from app.core.logger import logger
from app.services.storage import upload_file  # S3 ì—…ë¡œë“œìš© (í•„ìš” ì—†ìœ¼ë©´ ì‚­ì œ)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ì „ì—­ ìºì‹œ & Lazyâ€‘loader
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_pipe = None   # â˜… ìµœì´ˆì—” None

def _load_pipe():
    """â˜… í•„ìš”í•  ë•Œ í•œ ë²ˆë§Œ ë¶ˆëŸ¬ì˜¤ëŠ” ë‚´ë¶€ í•¨ìˆ˜"""
    global _pipe
    if _pipe is not None:                       # ì´ë¯¸ ë¡œë”©ë¨
        return _pipe

    if os.getenv("SKIP_MODEL_LOAD") == "1":
        raise RuntimeError("ğŸš« SKIP_MODEL_LOAD=1 ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ì•Šì•„ìš”!")

    if not torch.cuda.is_available():
        raise RuntimeError("ğŸš« GPU(CUDA)ê°€ í•„ìš”í•©ë‹ˆë‹¤. ë¡œì»¬ CPU í™˜ê²½ì—ì„œëŠ” SKIP_MODEL_LOAD=1ì„ ì£¼ê³  FastAPIë§Œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”!")

    logger.info("âš™ï¸  Loading CogVideoX1.5â€‘5B â€¦ (ì²« ì‹¤í–‰ë§Œ ì‹œê°„ì´ ê±¸ë ¤ìš”)")

    from diffusers import (
        AutoencoderKLCogVideoX,
        CogVideoXPipeline,
        CogVideoXTransformer3DModel,
    )
    from torchao.quantization import quantize_, int8_weight_only
    from transformers import BitsAndBytesConfig, T5EncoderModel

    _quant = int8_weight_only
    _bnb_cfg = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_use_double_quant=True,
        bnb_4bit_compute_dtype=torch.bfloat16,
    )

    # text encoder
    _text_enc = T5EncoderModel.from_pretrained(
        "THUDM/CogVideoX1.5-5B",
        subfolder="text_encoder",
        torch_dtype=torch.bfloat16,
    )
    quantize_(_text_enc, _quant())

    # transformer
    _xf = CogVideoXTransformer3DModel.from_pretrained(
        "THUDM/CogVideoX1.5-5B",
        subfolder="transformer",
        torch_dtype=torch.bfloat16,
    )
    quantize_(_xf, _quant())

    # VAE
    _vae = AutoencoderKLCogVideoX.from_pretrained(
        "THUDM/CogVideoX1.5-5B",
        subfolder="vae",
        torch_dtype=torch.bfloat16,
    )
    quantize_(_vae, _quant())

    _pipe = CogVideoXPipeline.from_pretrained(
        "THUDM/CogVideoX1.5-5B",
        text_encoder=_text_enc,
        transformer=_xf,
        vae=_vae,
        torch_dtype=torch.bfloat16,
        quantization_config=_bnb_cfg,
    )
    _pipe.enable_model_cpu_offload()
    _pipe.vae.enable_tiling()
    _pipe.vae.enable_slicing()

    logger.info("âœ…  CogVideoX íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ!")
    return _pipe

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. ë©”ì¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate(
    prompts: List[str],
    article_idx: int | str,
    upload: bool = False,
    out_dir: str | None = None,
) -> List[str]:
    """
    prompt ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ mp4 íŒŒì¼ë“¤ì„ ìƒì„±í•´ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
    """
    # â˜…â˜… í•„ìš” ì‹œ ì—¬ê¸°ì„œ ëª¨ë¸ì„ ì²˜ìŒ ë¡œë“œ
    pipe = _load_pipe()

    date_str = datetime.utcnow().strftime("%Y%m%d")
    base_dir = Path(out_dir or f"./output/ttv/{date_str}/{article_idx}")
    base_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"[TTV] output directory â†’ {base_dir}")

    result_paths: List[str] = []

    for i, prompt in enumerate(prompts):
        logger.info(f"[TTV] ({i+1}/{len(prompts)})  {prompt}")

        frames = pipe(
            prompt=prompt,
            num_videos_per_prompt=1,
            num_inference_steps=50,
            num_frames=40,
            guidance_scale=6,
            generator=torch.Generator(device="cuda").manual_seed(42),
        ).frames[0]

        local_mp4 = base_dir / f"output_{i}.mp4"
        export_to_video(frames, local_mp4.as_posix(), fps=8)
        logger.info(f"[TTV] saved â†’ {local_mp4}")
        result_paths.append(local_mp4.as_posix())

    # (ì„ íƒ) S3 ì—…ë¡œë“œ
    if upload:
        return [upload_file(p) for p in result_paths]

    return result_paths
