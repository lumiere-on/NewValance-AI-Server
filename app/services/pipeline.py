"""
services/pipeline.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í¬ë¡¤ë§ â†’ ë³¸ë¬¸ enrich â†’ GPT ìš”ì•½/í”„ë¡¬í”„íŠ¸ â†’ TTS â†’ íƒœê·¸ â†’ ë³‘í•©/ì¸ë„¤ì¼ â†’ S3 ì—…ë¡œë“œ
(í•œ ê¸°ì‚¬ = formal+casual ë‘ ë²„ì „)

ë³€ê²½ ë‚´ì—­ â­
- GPU ì˜ì¡´ì ì¸ TTV ë‹¨ê³„ ì œê±°
- gpt.mk_tags() í˜¸ì¶œë¡œ ìë™ íƒœê·¸ 4ê°œ ì‚°ì¶œ í›„ ì—…ë¡œë“œ ëª¨ë“ˆì— ì „ë‹¬
"""

from typing import List
from app.core.logger import logger
from app.services import (
    crawler,
    gpt,
    tts,
    ttv
)
from app.services.moviepy import build_and_upload


def run(sections: List[str] | None = None, upload: bool = True, limit: int = 5):
    """íŒŒì´í”„ë¼ì¸ ë©”ì¸ í•¨ìˆ˜

    Parameters
    ----------
    sections : list[str] | None
        ë„¤ì´ë²„ ì„¹ì…˜ ì½”ë“œ. None ì´ë©´ ì „ì²´ ì„¹ì…˜
    upload : bool, default True
        True â†’ S3 ì—…ë¡œë“œ, False â†’ ë¡œì»¬ ì €ì¥ë§Œ
    limit : int, default 5
        í…ŒìŠ¤íŠ¸ìš© ê¸°ì‚¬ ê°œìˆ˜ ì œí•œ
    """

    # 1) í—¤ë“œë¼ì¸ & ê¸°ì‚¬ ë³¸ë¬¸ -------------------------------------------------
    heads = crawler.crawl_headlines(sections)
    articles = crawler.enrich_articles(heads)[:limit]

    for art in articles:
  
        title = art["title"]
        idx   = str(art["index"])
        section = art["section"]
        news_url = art["url"]
        published_at = art["published_at"]
        
        # 2) GPT ìš”ì•½ ---------------------------------------------------------
        logger.info("[step] GPT sum start")

        summary = gpt.refine_news(art["content"])
        formal, casual = gpt.mk_TTS_prompt(summary)
        ttv_prompt = gpt.mk_TTV_prompt(formal)

        logger.info("[step] GPT sum end")

        # 3) íƒœê·¸ ì¶”ì¶œ --------------------------------------------------------
        logger.info("[step] Extract Tags start")
        tags = gpt.mk_tags(summary)  # ['ì •ì¹˜', 'ëŒ€í†µë ¹', 'ì˜ˆì‚°ì•ˆ', 'ê¸°í›„ìœ„ê¸°'] ë“±
        logger.info("[step] Extract Tags done")

        # 4) TTS ìƒì„± ---------------------------------------------------------
        tts_dir = f"./output/tts_tmp/{idx}"
        logger.info("[STEP] TTS synth start")
        formal_mp3 = tts.synthesize(" ".join(formal), "formal", f"{tts_dir}/formal.mp3")
        casual_mp3 = tts.synthesize(" ".join(casual), "casual", f"{tts_dir}/casual.mp3")

        logger.info("[STEP] TTS synth done")

        # 3) TTV
        video_dir = f"./output/ttv_tmp/{idx}"
        #ttv_paths = ttv.generate(ttv_prompt, article_idx=idx, upload=False, out_dir=video_dir)
        try:
            ttv_paths = ttv.generate(
                ttv_prompt,
                article_idx=idx,
                upload=True,
                out_dir=video_dir,
            )
        except RuntimeError as e:
            msg = str(e)
            if "SKIP_MODEL_LOAD=1" in msg:
                logger.info("ğŸš€ SKIP_MODEL_LOAD, TTV ë‹¨ê³„ ê±´ë„ˆëœ€")
                video_dir = None
            else:
                raise  # ê·¸ ì™¸ ì˜ˆì™¸ëŠ” ê·¸ëŒ€ë¡œ í„°ì§€ê²Œ

        # 5) ë³‘í•© + ì¸ë„¤ì¼ + íƒœê·¸ --------------------------------------------
        logger.info("[STEP] build_and_upload start")
        urls = build_and_upload(
            formal_subs   = formal,
            casual_subs   = casual,
            formal_mp3    = formal_mp3,
            casual_mp3    = casual_mp3,
            article_idx   = idx,
            news_title    = title,
            category_id   = section,
            original_url  = news_url,
            published_at  = published_at,
            summary_text  = summary,
            tags          = tags,         
            upload        = upload,
            video_dir     = video_dir        # TTV ì œê±°ë¡œ ë¹„ì›€/None ì²˜ë¦¬

        )

        logger.info(f"[PIPE] idx={idx} done â†’ {urls}")
